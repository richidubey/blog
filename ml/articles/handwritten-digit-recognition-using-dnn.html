<html>
    <head>
        <title>Live Handwritten Digits Recognition using Deep Neural Network</title>
        <link rel="stylesheet" href="articles.css">
    </head>
    <body>
        <h1>
            Live Handwritten Digits Recognition using Deep Neural Network
            <small>
                From <a href="../index.html">Machine Learning Blog by Richi</a>
            </small>
        </h1>
        <article>
            

            <p>
                Hi, Today we will design a tool that recognises your handwritten digit. It will
                use a deep neural network to decipher the digit you have written (between 0 -9).

                We will use two different DNN (Deep Neural Network) architectures and test both of them
                for this task, one would have series of Dense layers whereas the other would be CNN (Convolutional Neural Network).
            </p>
<br>
            <p>
                <h3>Step 1: Getting the data</h3>

                    We will use MNIST dataset to train our model.
                    The MNIST database of handwritten digits has a training set of 60,000 examples, and a test set of 10,000 examples. 
                    The digits have been size-normalized and centered in a fixed-size image. The images are greyscale and 28 by 28 pixels in size. 
                    <br><br>
                    These images are scanned handwriting samples from 250 people, half of whom were US Census Bureau employees, and half of whom were high school students.
                     
                    The test dataset is made up of digits written by a  different set of 250 people than the original training data (albeit still a group split between Census Bureau employees and high school students). This helps give us confidence that our system can recognize digits from people whose writing it didn't see during training (The model is trained on the training data and the evaluated on the test data).

                    <br><br>
                    The images in the dataset look like this:  
                    <br>
                    <img src="images/handwritten_digit_mnist_example.png">
                    
                    <br><br>
                    We will use keras to implement the model and to load,preprocess the data. We use keras because is a simple (and fast!) to use library which allows us to develop deep learning models without having to implement everything on our own. If you are really just starting out, implementing some of the basic things that keras automatically takes care of, like backtracking and gradient computation, can be helpful in understand how the neural networks actually work. Refer to <a href="https://colab.research.google.com/drive/15L51sdwIeylKQV-BZm2wCEfR9dJT7-Zi?usp=sharing" target="_blank">this</a> notebook to learn how to do these things on your own (without relying on a library). 
                    
                    <br><br>
                    We can load the dataset directly from keras, since keras includes a few dataset and MNIST happens to be a part of it. 
                    <br><br>
                    <div class="code">
                        (x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data(); 
                    </div>
            </p>

            <br>
            <p>
                <h3>Step 2: Visualizing the data</h3>
           

            Its always a good idea to look at and understand our data.

            <br><br>
            <code>print(x_train.shape)
                print(x_train[0].shape) 
                print(x_train[0])
            </code>

            <output>(60000, 28, 28) 
                    (28, 28) 
                    ...
                    [  0   0   0   0   0   0   0   0   0   0   0   0   3  18  18  18 126 136
                    175  26 166 255 247 127   0   0   0   0] 
                    ... 
            </output>
            <br>
            This shows that our training data has 60000 images of 28*28 pixel values, with pixel values ranging from 0-255. Lets print one of the images.

            <br><br>
            <code>from matplotlib import pyplot

                pyplot.imshow(x_train[0], cmap=pyplot.get_cmap('gray'))
                <comment>#cmap indicates color map (scheme).</comment>
                pyplot.show()
            </code>

            <output>
                    <img src="images/handwritten_digit_mnist_code_2.png">
            </output>

            <br>
            Our image data is in a greyscale format, this means that
            each pixel value actually denotes the intensity of that pixel, i.e. how dark that pixel is - ranging from 0 (completely white) to 255 (pitch dark). Other format that images take are RGB and RGBA (A for alpha channel - which indicates the opacity of a pixel). For the latter two formats, the shapes would be (height, width, 3) and (height, width, 4) respectively.

        </p>

        <br>
        <p>
            <h3>Step 3: Defining the model</h3>
            
            We will set up two different models. One that uses a dense layer after flattening the 28*28 image, whereas the other would use CNN.
            
            <br><br>
            Lets implement the first model.
            
            <br>
            <code>inputs = keras.Input(shape = (28,28))

            x = keras.layers.Rescaling(1.0 / 255) (inputs) <comment>#This is used to change the range of inputs. When we rescale our input (which is in range [0,255]) by 1/255, our inputs get translated to range [0,1]. </comment>

            <!-- #print(x.shape)  -->
            x = keras.layers.Flatten()(x) <comment>#This flattens the input, which means that it converts our 28 * 28 matrix image into a 784 linear array image. </comment>
            
            <!-- #print(x.shape) -->
            x = keras.layers.Dense( 128, activation = "relu" )(x) <comment>#relu ouputs the original input value if it is positive, otherwise it outputs zero </comment>
            
            x = keras.layers.Dense( 128, activation = "relu" )(x)

            outputs = keras.layers.Dense(10, activation = "softmax")(x) <comment> #10 output because we are categorizing the handwritten digits in 0-9.</comment>

            model = keras.Model(inputs, outputs)
model.summary() 
            </code>
            <output style="white-space: pre;">Model: "model"
                _________________________________________________________________
                Layer (type)                Output Shape              Param #   
                =================================
                 input_1 (InputLayer)        [(None, 28, 28)]          0         
                                                                                 
                 rescaling (Rescaling)       (None, 28, 28)            0         
                                                                                 
                 flatten (Flatten)           (None, 784)               0         
                                                                                 
                 dense (Dense)               (None, 128)               100480    
                                                                                 
                 dense_1 (Dense)             (None, 128)               16512     
                                                                                 
                 dense_2 (Dense)             (None, 10)                1290      
                                                                                 
                ==================================
                Total params: 118,282
                Trainable params: 118,282
                Non-trainable params: 0
                ______________________________
            </output>
            <br>
            None as the first value in the input shape indicates that the model can take in any number (batch-size) of inputs (with 28 * 28 dimension)

            <br><br>
            Lets implement the second model. The second model uses CNN  (Convolutional Neural Network) architecture. Convolutional models perform better than traditional dense models on image data. This is because CNN models are translation-invariant (more specifically, the Convolutional layer is translation equivariant) - which means that no matter where an object lies in an image, the model would still be able to detect the object. So, if a person writes a '7' in top right of our 28*28 image, the model would still be able to predict that 7 even if it was only trained on images of '7' where it was written in bottom left of the image.   

<code>model_cnn = keras.Sequential(
        [
         keras.Input(shape = (28,28,1)),
         layers.Conv2D(32, kernel_size=(3,3), activation="relu"),
         layers.MaxPooling2D(pool_size = (2,2)),
         layers.Conv2D(64, kernel_size = (3,3), activation="relu"),
         layers.MaxPooling2D(pool_size=(2,2)),
         layers.Flatten(),
         layers.Dropout(0.5),
         layers.Dense(10, activation = "softmax")<comment> #Since output can be between 0-9, we have 10 as number of output nodes in Dense layer</comment>
        ]
    )
    
    model_cnn.summary()
</code>



          
        </article>
    </body>

</html>